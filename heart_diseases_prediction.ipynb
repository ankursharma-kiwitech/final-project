{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heart_diseases_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyC0/FfdoKJ+gcXyp7u3e3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankursharma-kiwitech/final-project/blob/master/heart_diseases_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "topYolb7Y6ny"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# data wrangling & pre-processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#model validation\n",
        "from sklearn.metrics import log_loss,roc_auc_score,precision_score,f1_score,recall_score,roc_curve,auc\n",
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score,fbeta_score,matthews_corrcoef\n",
        "from sklearn import metrics\n",
        "\n",
        "# cross validation\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# machine learning algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier,VotingClassifier,AdaBoostClassifier,GradientBoostingClassifier,RandomForestClassifier,ExtraTreesClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC \n",
        "import xgboost as xgb\n",
        "\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = pd.read_csv('/content/heart_statlog_cleveland_hungary_final.csv')"
      ],
      "metadata": {
        "id": "pO3fCSiIacuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt.head()"
      ],
      "metadata": {
        "id": "2kmlFbhoac3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n",
        "       'exercise_induced_angina', 'st_depression', 'st_slope','target']"
      ],
      "metadata": {
        "id": "QAmtQztGac5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting features to categorical features \n",
        "\n",
        "dt['chest_pain_type'][dt['chest_pain_type'] == 1] = 'typical angina'\n",
        "dt['chest_pain_type'][dt['chest_pain_type'] == 2] = 'atypical angina'\n",
        "dt['chest_pain_type'][dt['chest_pain_type'] == 3] = 'non-anginal pain'\n",
        "dt['chest_pain_type'][dt['chest_pain_type'] == 4] = 'asymptomatic'\n",
        "\n",
        "\n",
        "\n",
        "dt['rest_ecg'][dt['rest_ecg'] == 0] = 'normal'\n",
        "dt['rest_ecg'][dt['rest_ecg'] == 1] = 'ST-T wave abnormality'\n",
        "dt['rest_ecg'][dt['rest_ecg'] == 2] = 'left ventricular hypertrophy'\n",
        "\n",
        "\n",
        "\n",
        "dt['st_slope'][dt['st_slope'] == 1] = 'upsloping'\n",
        "dt['st_slope'][dt['st_slope'] == 2] = 'flat'\n",
        "dt['st_slope'][dt['st_slope'] == 3] = 'downsloping'\n",
        "\n",
        "dt[\"sex\"] = dt.sex.apply(lambda  x:'male' if x==1 else 'female')\n"
      ],
      "metadata": {
        "id": "atvqsCE3ac8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt['chest_pain_type'].value_counts()"
      ],
      "metadata": {
        "id": "bx9NW8W_ac-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt['rest_ecg'].value_counts()"
      ],
      "metadata": {
        "id": "WfFAwLNjadBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt['st_slope'].value_counts()"
      ],
      "metadata": {
        "id": "sHKiJcHCcp8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping row with st_slope =0\n",
        "dt.drop(dt[dt.st_slope ==0].index, inplace=True)\n",
        "#checking distribution\n",
        "dt['st_slope'].value_counts()"
      ],
      "metadata": {
        "id": "zxe6SxwRcp_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the top 5 entries of dataset after feature encoding\n",
        "dt.head()"
      ],
      "metadata": {
        "id": "pbXoPNM6cqBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking missing entries in the dataset columnwise\n",
        "dt.isna().sum()"
      ],
      "metadata": {
        "id": "zKMS0XYVcqDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first checking the shape of the dataset\n",
        "dt.shape"
      ],
      "metadata": {
        "id": "uEb3axhxcqFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary statistics of numerical columns\n",
        "dt.describe(include =[np.number])"
      ],
      "metadata": {
        "id": "jSsR1ynPcqHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary statistics of categorical columns\n",
        "dt.describe(include =[np.object])"
      ],
      "metadata": {
        "id": "jfXaxU__cqJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting attrition of employees\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharey=False, figsize=(14,6))\n",
        "\n",
        "ax1 = dt['target'].value_counts().plot.pie( x=\"Heart disease\" ,y ='no.of patients', \n",
        "                   autopct = \"%1.0f%%\",labels=[\"Heart Disease\",\"Normal\"], startangle = 60,ax=ax1);\n",
        "ax1.set(title = 'Percentage of Heart disease patients in Dataset')\n",
        "\n",
        "ax2 = dt[\"target\"].value_counts().plot(kind=\"barh\" ,ax =ax2)\n",
        "for i,j in enumerate(dt[\"target\"].value_counts().values):\n",
        "    ax2.text(.5,i,j,fontsize=12)\n",
        "ax2.set(title = 'No. of Heart disease patients in Dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dcs1Yl8AcqK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,12))\n",
        "plt.subplot(221)\n",
        "dt[\"sex\"].value_counts().plot.pie(autopct = \"%1.0f%%\",colors = sns.color_palette(\"prism\",5),startangle = 60,labels=[\"Male\",\"Female\"],\n",
        "wedgeprops={\"linewidth\":2,\"edgecolor\":\"k\"},explode=[.1,.1],shadow =True)\n",
        "plt.title(\"Distribution of Gender\")\n",
        "plt.subplot(222)\n",
        "ax= sns.distplot(dt['age'], rug=True)\n",
        "plt.title(\"Age wise distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wp0ZK9w6cqNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating separate df for normal and heart patients\n",
        "\n",
        "attr_1=dt[dt['target']==1]\n",
        "\n",
        "attr_0=dt[dt['target']==0]\n",
        "\n",
        "# plotting normal patients\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "ax1 = plt.subplot2grid((1,2),(0,0))\n",
        "sns.distplot(attr_0['age'])\n",
        "plt.title('AGE DISTRIBUTION OF NORMAL PATIENTS', fontsize=15, weight='bold')\n",
        "\n",
        "ax1 = plt.subplot2grid((1,2),(0,1))\n",
        "sns.countplot(attr_0['sex'], palette='viridis')\n",
        "plt.title('GENDER DISTRIBUTION OF NORMAL PATIENTS', fontsize=15, weight='bold' )\n",
        "plt.show()\n",
        "\n",
        "#plotting heart patients\n",
        "\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "ax1 = plt.subplot2grid((1,2),(0,0))\n",
        "sns.distplot(attr_1['age'])\n",
        "plt.title('AGE DISTRIBUTION OF HEART DISEASE PATIENTS', fontsize=15, weight='bold')\n",
        "\n",
        "ax1 = plt.subplot2grid((1,2),(0,1))\n",
        "sns.countplot(attr_1['sex'], palette='viridis')\n",
        "plt.title('GENDER DISTRIBUTION OF HEART DISEASE PATIENTS', fontsize=15, weight='bold' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qHtQBnNMcqPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting normal patients\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "ax1 = plt.subplot2grid((1,2),(0,0))\n",
        "sns.countplot(attr_0['chest_pain_type'])\n",
        "plt.title('CHEST PAIN OF NORMAL PATIENTS', fontsize=15, weight='bold')\n",
        "\n",
        "#plotting heart patients\n",
        "ax1 = plt.subplot2grid((1,2),(0,1))\n",
        "sns.countplot(attr_1['chest_pain_type'], palette='viridis')\n",
        "plt.title('CHEST PAIN OF HEART PATIENTS', fontsize=15, weight='bold' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kHZ8XCzacqRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring the Heart Disease patients based on Chest Pain Type\n",
        "plot_criteria= ['chest_pain_type', 'target']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(dt[plot_criteria[0]], dt[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)"
      ],
      "metadata": {
        "id": "Z1zbGf73cqTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting normal patients\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "ax1 = plt.subplot2grid((1,2),(0,0))\n",
        "sns.countplot(attr_0['rest_ecg'])\n",
        "plt.title('REST ECG OF NORMAL PATIENTS', fontsize=15, weight='bold')\n",
        "\n",
        "#plotting heart patients\n",
        "ax1 = plt.subplot2grid((1,2),(0,1))\n",
        "sns.countplot(attr_1['rest_ecg'], palette='viridis')\n",
        "plt.title('REST ECG OF HEART PATIENTS', fontsize=15, weight='bold' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tsMYTZLZd5YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring the Heart Disease patients based on REST ECG\n",
        "plot_criteria= ['rest_ecg', 'target']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(dt[plot_criteria[0]], dt[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n"
      ],
      "metadata": {
        "id": "yjto5vc0d5ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting normal patients\n",
        "fig = plt.figure(figsize=(15,5))\n",
        "ax1 = plt.subplot2grid((1,2),(0,0))\n",
        "sns.countplot(attr_0['st_slope'])\n",
        "plt.title('ST SLOPE OF NORMAL PATIENTS', fontsize=15, weight='bold')\n",
        "\n",
        "#plotting heart patients\n",
        "ax1 = plt.subplot2grid((1,2),(0,1))\n",
        "sns.countplot(attr_1['st_slope'], palette='viridis')\n",
        "plt.title('ST SLOPE OF HEART PATIENTS', fontsize=15, weight='bold' )\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y4PXAtg0d5dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploring the Heart Disease patients based on ST Slope\n",
        "plot_criteria= ['st_slope', 'target']\n",
        "cm = sns.light_palette(\"red\", as_cmap=True)\n",
        "(round(pd.crosstab(dt[plot_criteria[0]], dt[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)\n"
      ],
      "metadata": {
        "id": "8PSZc3Icd5fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(dt, hue = 'target', vars = ['age', 'resting_blood_pressure', 'cholesterol'] )\n"
      ],
      "metadata": {
        "id": "udLBuQy1d5hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x = 'resting_blood_pressure', y = 'cholesterol', hue = 'target', data = dt)\n"
      ],
      "metadata": {
        "id": "_gzr2jP6d5ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x = 'resting_blood_pressure', y = 'age', hue = 'target', data = dt)\n"
      ],
      "metadata": {
        "id": "oBUbyRgJd5mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering numeric features as age , resting bp, cholestrol and max heart rate achieved has outliers as per EDA\n",
        "\n",
        "dt_numeric = dt[['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved']]"
      ],
      "metadata": {
        "id": "L6PlgPn5d5oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_numeric.head()\n"
      ],
      "metadata": {
        "id": "LC0NYvsTd5qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating zscore of numeric columns in the dataset\n",
        "z = np.abs(stats.zscore(dt_numeric))\n",
        "print(z)\n"
      ],
      "metadata": {
        "id": "LLbtYvJAd5sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining threshold for filtering outliers \n",
        "threshold = 3\n",
        "print(np.where(z > 3))\n"
      ],
      "metadata": {
        "id": "ezfpQjbmd5vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtering outliers retaining only those data points which are below threshhold\n",
        "dt = dt[(z < 3).all(axis=1)]\n"
      ],
      "metadata": {
        "id": "IMucSOeid5xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking shape of dataset after outlier removal\n",
        "dt.shape"
      ],
      "metadata": {
        "id": "e0tmUVHWd5zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## encoding categorical variables\n",
        "dt = pd.get_dummies(dt, drop_first=True)\n",
        "\n",
        "dt.head()"
      ],
      "metadata": {
        "id": "5UROQ_sGd51y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the shape of dataset\n",
        "dt.shape\n"
      ],
      "metadata": {
        "id": "jk3tFL8ad54N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# segregating dataset into features i.e., X and target variables i.e., y\n",
        "X = dt.drop(['target'],axis=1)\n",
        "y = dt['target']"
      ],
      "metadata": {
        "id": "X3T9ikmWd56G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation with Response Variable class\n",
        "\n",
        "X.corrwith(y).plot.bar(\n",
        "        figsize = (16, 4), title = \"Correlation with Diabetes\", fontsize = 15,\n",
        "        rot = 90, grid = True)"
      ],
      "metadata": {
        "id": "uwzpfYM3d59N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2,shuffle= True , random_state=5)\n"
      ],
      "metadata": {
        "id": "GI6pRqr2cqW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## checking distribution of traget variable in train test split\n",
        "print('Distribution of traget variable in training set')\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print('Distribution of traget variable in test set')\n",
        "print(y_test.value_counts())"
      ],
      "metadata": {
        "id": "vHfYY0x2gseY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('------------Training Set------------------')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('------------Test Set------------------')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "id": "Rnp71nQlgsgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature normalization\n",
        "In this step we will normalize all the numeric feature in the range of 0 to 1"
      ],
      "metadata": {
        "id": "_EG3yUmXhFYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train[['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression']] = scaler.fit_transform(X_train[['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression']])\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "Q89Mbzp-gsjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression']] = scaler.transform(X_test[['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression']])\n",
        "X_test.head()"
      ],
      "metadata": {
        "id": "ixR02jA-gsla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we will build different baseline models and perform 10-fold cross validation to filter top performing baseline models to be used in level 0 of stacked ensemble method."
      ],
      "metadata": {
        "id": "RgguNaLbhREg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import xgboost as xgb\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import *\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# function initializing baseline machine learning models\n",
        "def GetBasedModel():\n",
        "    basedModels = []\n",
        "    basedModels.append(('LR_L2'   , LogisticRegression(penalty='l2')))\n",
        "    basedModels.append(('LDA'  ,  LinearDiscriminantAnalysis()))\n",
        "    basedModels.append(('KNN7'  , KNeighborsClassifier(7)))\n",
        "    basedModels.append(('KNN5'  , KNeighborsClassifier(5)))\n",
        "    basedModels.append(('KNN9'  , KNeighborsClassifier(9)))\n",
        "    basedModels.append(('KNN11'  , KNeighborsClassifier(11)))\n",
        "    basedModels.append(('CART' , DecisionTreeClassifier()))\n",
        "    basedModels.append(('NB'   , GaussianNB()))\n",
        "    basedModels.append(('SVM Linear'  , SVC(kernel='linear',gamma='auto',probability=True)))\n",
        "    basedModels.append(('SVM RBF'  , SVC(kernel='rbf',gamma='auto',probability=True)))\n",
        "    basedModels.append(('AB'   , AdaBoostClassifier()))\n",
        "    basedModels.append(('GBM'  , GradientBoostingClassifier(n_estimators=100,max_features='sqrt')))\n",
        "    basedModels.append(('RF_Ent100'   , RandomForestClassifier(criterion='entropy',n_estimators=100)))\n",
        "    basedModels.append(('RF_Gini100'   , RandomForestClassifier(criterion='gini',n_estimators=100)))\n",
        "    basedModels.append(('ET100'   , ExtraTreesClassifier(n_estimators= 100)))\n",
        "    basedModels.append(('ET500'   , ExtraTreesClassifier(n_estimators= 500)))\n",
        "    basedModels.append(('MLP', MLPClassifier()))\n",
        "    basedModels.append(('SGD3000', SGDClassifier(max_iter=1000, tol=1e-4)))\n",
        "    basedModels.append(('XGB_2000', xgb.XGBClassifier(n_estimators= 2000)))\n",
        "    basedModels.append(('XGB_500', xgb.XGBClassifier(n_estimators= 500)))\n",
        "    basedModels.append(('XGB_100', xgb.XGBClassifier(n_estimators= 100)))\n",
        "    basedModels.append(('XGB_1000', xgb.XGBClassifier(n_estimators= 1000)))\n",
        "    basedModels.append(('ET1000'   , ExtraTreesClassifier(n_estimators= 1000)))\n",
        "    \n",
        "    return basedModels\n",
        "\n",
        "# function for performing 10-fold cross validation of all the baseline models\n",
        "def BasedLine2(X_train, y_train,models):\n",
        "    # Test options and evaluation metric\n",
        "    num_folds = 10\n",
        "    scoring = 'accuracy'\n",
        "    seed = 7\n",
        "    results = []\n",
        "    names = []\n",
        "    for name, model in models:\n",
        "        kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "        cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "        results.append(cv_results)\n",
        "        names.append(name)\n",
        "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "        print(msg)\n",
        "         \n",
        "        \n",
        "    return results,msg"
      ],
      "metadata": {
        "id": "YFon2m5Zgsnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "models = GetBasedModel() \n",
        "names , results = BasedLine2 (X_train, y_train,  models)"
      ],
      "metadata": {
        "id": "rumaBfMJgsp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_ent = RandomForestClassifier(criterion='entropy',n_estimators=100)\n",
        "rf_ent.fit(X_train, y_train)\n",
        "y_pred_rfe = rf_ent.predict(X_test)"
      ],
      "metadata": {
        "id": "asKh7lI5gssS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train,y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)"
      ],
      "metadata": {
        "id": "pEd9fKqfgsub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K nearest neighbour (n=9)"
      ],
      "metadata": {
        "id": "YBsURqwZmz5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(9)\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred_knn = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "3lxq6Dz4gswk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra Tree Classifier (n_estimators=500)"
      ],
      "metadata": {
        "id": "9HGe0mxkm202"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "et_100 = ExtraTreesClassifier(n_estimators= 100)\n",
        "et_100.fit(X_train,y_train)\n",
        "y_pred_et_100 = et_100.predict(X_test)"
      ],
      "metadata": {
        "id": "XYu87xksgsy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost (n_estimators=500)"
      ],
      "metadata": {
        "id": "DEW8YlF4m_K2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "xgb = xgb.XGBClassifier(n_estimators= 500)\n",
        "xgb.fit(X_train,y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "36piEhO1gs0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Classifier (kernel='linear')"
      ],
      "metadata": {
        "id": "Q7cl7qgynB8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(kernel='linear',gamma='auto',probability=True)\n",
        "svc.fit(X_train,y_train)\n",
        "y_pred_svc = svc.predict(X_test)"
      ],
      "metadata": {
        "id": "YQbTOJmVgs3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "ZLHXlhpGnMXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGDClassifier(max_iter=1000, tol=1e-4)\n",
        "sgd.fit(X_train,y_train)\n",
        "y_pred_sgd = sgd.predict(X_test)"
      ],
      "metadata": {
        "id": "RL2QgCmkgs6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adaboost Classifier"
      ],
      "metadata": {
        "id": "J6Vqsp05nUqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train,y_train)\n",
        "y_pred_ada = ada.predict(X_test)"
      ],
      "metadata": {
        "id": "kZarvUufnVd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "decision Tree Classifier (CART)"
      ],
      "metadata": {
        "id": "fXeKd_NunYaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decc = DecisionTreeClassifier()\n",
        "decc.fit(X_train,y_train)\n",
        "y_pred_decc = decc.predict(X_test)\n"
      ],
      "metadata": {
        "id": "-JsQgVQsnVgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gradient boosting machine"
      ],
      "metadata": {
        "id": "1LGkNugQneke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbm = GradientBoostingClassifier(n_estimators=100,max_features='sqrt')\n",
        "gbm.fit(X_train,y_train)\n",
        "y_pred_gbm = gbm.predict(X_test)"
      ],
      "metadata": {
        "id": "0l_MI5ndnVi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vVCf3RNZnVmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Model Evaluation\n",
        "In this step we will first define which evaluation metrics we will use to evaluate our model. The most important evaluation metric for this problem domain is sensitivity, specificity, Precision, F1-measure, Geometric mean and mathew correlation coefficient and finally ROC AUC curve\n",
        "\n",
        "Mathew Correlation coefficient (MCC)\n",
        "The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories (true positives, false negatives, true negatives, and false positives), proportionally both to the size of positive elements and the size of negative elements in the dataset.\n",
        "\n",
        "\n",
        "\n",
        "Log Loss\n",
        "Logarithmic loss measures the performance of a classification model where the prediction input is a probability value between 0 and 1. The goal of our machine learning models is to minimize this value. A perfect model would have a log loss of 0. Log loss increases as the predicted probability diverges from the actual label. So predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high log loss.\n",
        "\n",
        "The graph below shows the range of possible log loss values given a true observation (isDog = 1). As the predicted probability approaches 1, log loss slowly decreases. As the predicted probability decreases, however, the log loss increases rapidly. Log loss penalizes both types of errors, but especially those predications that are confident and wrong!\n",
        "\n",
        "\n",
        "\n",
        "F1 Score\n",
        "F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall. In our case, F1 score is 0.701.\n",
        "\n",
        "F1 Score = 2(Recall Precision) / (Recall + Precision)"
      ],
      "metadata": {
        "id": "S0cu31P3nnfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CM=confusion_matrix(y_test,y_pred_rfe)\n",
        "sns.heatmap(CM, annot=True)\n",
        "\n",
        "TN = CM[0][0]\n",
        "FN = CM[1][0]\n",
        "TP = CM[1][1]\n",
        "FP = CM[0][1]\n",
        "specificity = TN/(TN+FP)\n",
        "loss_log = log_loss(y_test, y_pred_rfe)\n",
        "acc= accuracy_score(y_test, y_pred_rfe)\n",
        "roc=roc_auc_score(y_test, y_pred_rfe)\n",
        "prec = precision_score(y_test, y_pred_rfe)\n",
        "rec = recall_score(y_test, y_pred_rfe)\n",
        "f1 = f1_score(y_test, y_pred_rfe)\n",
        "\n",
        "mathew = matthews_corrcoef(y_test, y_pred_rfe)\n",
        "model_results =pd.DataFrame([['Random Forest',acc, prec,rec,specificity, f1,roc, loss_log,mathew]],\n",
        "               columns = ['Model', 'Accuracy','Precision', 'Sensitivity','Specificity', 'F1 Score','ROC','Log_Loss','mathew_corrcoef'])\n",
        "\n",
        "model_results"
      ],
      "metadata": {
        "id": "lAUCJk99nVrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison with other Models"
      ],
      "metadata": {
        "id": "cNuY1q1BnwiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {        'MLP': y_pred_mlp, \n",
        "                'KNN': y_pred_knn, \n",
        "                'EXtra tree classifier': y_pred_et_100,\n",
        "                'XGB': y_pred_xgb, \n",
        "                'SVC': y_pred_svc, \n",
        "                'SGD': y_pred_sgd,\n",
        "                'Adaboost': y_pred_ada, \n",
        "                'CART': y_pred_decc, \n",
        "                'GBM': y_pred_gbm }\n",
        "\n",
        "models = pd.DataFrame(data) \n",
        " \n",
        "for column in models:\n",
        "    CM=confusion_matrix(y_test,models[column])\n",
        "    \n",
        "    TN = CM[0][0]\n",
        "    FN = CM[1][0]\n",
        "    TP = CM[1][1]\n",
        "    FP = CM[0][1]\n",
        "    specificity = TN/(TN+FP)\n",
        "    loss_log = log_loss(y_test, models[column])\n",
        "    acc= accuracy_score(y_test, models[column])\n",
        "    roc=roc_auc_score(y_test, models[column])\n",
        "    prec = precision_score(y_test, models[column])\n",
        "    rec = recall_score(y_test, models[column])\n",
        "    f1 = f1_score(y_test, models[column])\n",
        "    \n",
        "    mathew = matthews_corrcoef(y_test, models[column])\n",
        "    results =pd.DataFrame([[column,acc, prec,rec,specificity, f1,roc, loss_log,mathew]],\n",
        "               columns = ['Model', 'Accuracy','Precision', 'Sensitivity','Specificity', 'F1 Score','ROC','Log_Loss','mathew_corrcoef'])\n",
        "    model_results = model_results.append(results, ignore_index = True)\n",
        "\n",
        "model_results"
      ],
      "metadata": {
        "id": "PLhTQbyEnVtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Findings\n",
        "AS we can see from above results, XGBoost Classifier is best performer as it has highest test accuracy of 0.9191, sensitivity of 0.943 and specificity of 0.89 and highest f1-score of 0.9243 and lowest Log Loss of 2079."
      ],
      "metadata": {
        "id": "5AfX2QpDn36Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC AUC Curve"
      ],
      "metadata": {
        "id": "42gER4VBn5Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def roc_auc_plot(y_true, y_proba, label=' ', l='-', lw=1.0):\n",
        "    from sklearn.metrics import roc_curve, roc_auc_score\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba[:,1])\n",
        "    ax.plot(fpr, tpr, linestyle=l, linewidth=lw,\n",
        "            label=\"%s (area=%.3f)\"%(label,roc_auc_score(y_true, y_proba[:,1])))\n",
        "\n",
        "f, ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "\n",
        "roc_auc_plot(y_test,rf_ent.predict_proba(X_test),label='Random Forest Classifier ',l='-')\n",
        "roc_auc_plot(y_test,et_100.predict_proba(X_test),label='Extra Tree Classifier ',l='-')\n",
        "roc_auc_plot(y_test,xgb.predict_proba(X_test),label='XGboost',l='-')\n",
        "\n",
        "ax.plot([0,1], [0,1], color='k', linewidth=0.5, linestyle='--', \n",
        "        )    \n",
        "ax.legend(loc=\"lower right\")    \n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "ax.set_title('Receiver Operator Characteristic curves')\n",
        "sns.despine()"
      ],
      "metadata": {
        "id": "ApCcA55anVxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision Recall curve"
      ],
      "metadata": {
        "id": "PPZAlHiuoCOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_plot(y_true, y_proba, label=' ', l='-', lw=1.0):\n",
        "    from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "    precision, recall, _ = precision_recall_curve(y_test,\n",
        "                                                  y_proba[:,1])\n",
        "    average_precision = average_precision_score(y_test, y_proba[:,1],\n",
        "                                                     average=\"micro\")\n",
        "    ax.plot(recall, precision, label='%s (average=%.3f)'%(label,average_precision),\n",
        "            linestyle=l, linewidth=lw)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(14,10))\n",
        "\n",
        "precision_recall_plot(y_test,rf_ent.predict_proba(X_test),label='Random Forest Classifier ',l='-')\n",
        "precision_recall_plot(y_test,et_100.predict_proba(X_test),label='Extra Tree Classifier ',l='-')\n",
        "precision_recall_plot(y_test,xgb.predict_proba(X_test),label='XGboost',l='-')\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.legend(loc=\"lower left\")\n",
        "ax.grid(True)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "ax.set_title('Precision-recall curves')\n",
        "sns.despine()"
      ],
      "metadata": {
        "id": "YH7oX4B_nVz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Feature Selection"
      ],
      "metadata": {
        "id": "H9w_hjNAoLDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_feats=11\n",
        "\n",
        "def cor_selector(X, y,num_feats):\n",
        "    cor_list = []\n",
        "    feature_name = X.columns.tolist()\n",
        "    # calculate the correlation with y for each feature\n",
        "    for i in X.columns.tolist():\n",
        "        cor = np.corrcoef(X[i], y)[0, 1]\n",
        "        cor_list.append(cor)\n",
        "    # replace NaN with 0\n",
        "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
        "    # feature name\n",
        "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
        "    # feature selection? 0 for not select, 1 for select\n",
        "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
        "    return cor_support, cor_feature\n",
        "cor_support, cor_feature = cor_selector(X, y,num_feats)\n",
        "print(str(len(cor_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "4ibvypFmnV2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "X_norm = MinMaxScaler().fit_transform(X)\n",
        "chi_selector = SelectKBest(chi2, k=num_feats)\n",
        "chi_selector.fit(X_norm, y)\n",
        "chi_support = chi_selector.get_support()\n",
        "chi_feature = X.loc[:,chi_support].columns.tolist()\n",
        "print(str(len(chi_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "nAjqw21VnV4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=num_feats, step=10, verbose=5)\n",
        "rfe_selector.fit(X_norm, y)\n",
        "rfe_support = rfe_selector.get_support()\n",
        "rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
        "print(str(len(rfe_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "7_KLyupboVDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9VVzOBYMoVLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l2\", solver='lbfgs'), max_features=num_feats)\n",
        "embeded_lr_selector.fit(X_norm, y)\n",
        "\n",
        "embeded_lr_support = embeded_lr_selector.get_support()\n",
        "embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
        "print(str(len(embeded_lr_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "VLdzAZZZoVSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UToHhCnloVZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100, criterion='gini'), max_features=num_feats)\n",
        "embeded_rf_selector.fit(X, y)\n",
        "\n",
        "embeded_rf_support = embeded_rf_selector.get_support()\n",
        "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
        "print(str(len(embeded_rf_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "4efHhut0oVgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bmLplAuroVmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
        "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
        "\n",
        "embeded_lgb_selector = SelectFromModel(lgbc, max_features=num_feats)\n",
        "embeded_lgb_selector.fit(X, y)\n",
        "\n",
        "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
        "embeded_lgb_feature = X.loc[:,embeded_lgb_support].columns.tolist()\n",
        "print(str(len(embeded_lgb_feature)), 'selected features')"
      ],
      "metadata": {
        "id": "bs-_sP-VoVsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put all selection together\n",
        "feature_name = X.columns\n",
        "feature_selection_df = pd.DataFrame({'Feature':feature_name, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'Logistics':embeded_lr_support,\n",
        "                                    'Random Forest':embeded_rf_support, 'LightGBM':embeded_lgb_support})\n",
        "# count the selected times for each feature\n",
        "feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
        "# display the top 100\n",
        "feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
        "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
        "feature_selection_df.head(num_feats)"
      ],
      "metadata": {
        "id": "4TIJVnTEokhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# segregating dataset into features i.e., X and target variables i.e., y\n",
        "X = dt.drop(['target','resting_blood_pressure','sex_male','chest_pain_type_non-anginal pain','chest_pain_type_atypical angina'],axis=1)\n",
        "y = dt['target']"
      ],
      "metadata": {
        "id": "Z__4h1MFoof2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2,shuffle=True, random_state=5)"
      ],
      "metadata": {
        "id": "_epSecLLookQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train[['age','cholesterol','max_heart_rate_achieved','st_depression']] = scaler.fit_transform(X_train[['age','cholesterol','max_heart_rate_achieved','st_depression']])\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "7Kat0INioomb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[['age','cholesterol','max_heart_rate_achieved','st_depression']] = scaler.transform(X_test[['age','cholesterol','max_heart_rate_achieved','st_depression']])\n",
        "X_test.head()"
      ],
      "metadata": {
        "id": "t34vk8UgootN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "models = GetBasedModel()\n",
        "names,results = BasedLine2(X_train, y_train,models)"
      ],
      "metadata": {
        "id": "h4EoxHstoov2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Soft voting"
      ],
      "metadata": {
        "id": "jhg4GZgRpBVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "clf1=RandomForestClassifier(criterion='entropy',n_estimators=100)\n",
        "\n",
        "clf2=DecisionTreeClassifier()\n",
        "clf3=xgb.XGBClassifier(n_estimators= 1000)\n",
        "clf4=ExtraTreesClassifier(n_estimators= 500)\n",
        "\n",
        "clf5=GradientBoostingClassifier(n_estimators=100,max_features='sqrt')\n",
        "\n",
        "\n",
        "eclf1 = VotingClassifier(estimators=[('rfe', clf1), ('decc', clf2), ('xgb', clf3),('ET',clf4),('gb',clf5),], \n",
        "                         voting='soft', weights=[4,1,2,3,1])\n",
        "eclf1.fit(X_train,y_train)\n",
        "y_pred_sv =eclf1.predict(X_test)"
      ],
      "metadata": {
        "id": "OOKaWQoLoo0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "QESDdhk9pDA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CM=confusion_matrix(y_test,y_pred_sv)\n",
        "sns.heatmap(CM, annot=True)\n",
        "\n",
        "TN = CM[0][0]\n",
        "FN = CM[1][0]\n",
        "TP = CM[1][1]\n",
        "FP = CM[0][1]\n",
        "specificity = TN/(TN+FP)\n",
        "loss_log = log_loss(y_test, y_pred_sv)\n",
        "acc= accuracy_score(y_test, y_pred_sv)\n",
        "roc=roc_auc_score(y_test, y_pred_sv)\n",
        "prec = precision_score(y_test, y_pred_sv)\n",
        "rec = recall_score(y_test, y_pred_sv)\n",
        "f1 = f1_score(y_test, y_pred_sv)\n",
        "\n",
        "mathew = matthews_corrcoef(y_test, y_pred_sv)\n",
        "model_results =pd.DataFrame([['Soft Voting',acc, prec,rec,specificity, f1,roc, loss_log,mathew]],\n",
        "               columns = ['Model', 'Accuracy','Precision', 'Sensitivity','Specificity', 'F1 Score','ROC','Log_Loss','mathew_corrcoef'])\n",
        "\n",
        "model_results"
      ],
      "metadata": {
        "id": "k6IzlaUnoo2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_ent = RandomForestClassifier(criterion='entropy',n_estimators=100)\n",
        "rf_ent.fit(X_train, y_train)\n",
        "y_pred_rfe = rf_ent.predict(X_test)\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train,y_train)\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "knn = KNeighborsClassifier(9)\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "et_1000 = ExtraTreesClassifier(n_estimators= 1000)\n",
        "et_1000.fit(X_train,y_train)\n",
        "y_pred_et1000 = et_1000.predict(X_test)\n",
        "xgb = xgb.XGBClassifier(n_estimators= 1000)\n",
        "xgb.fit(X_train,y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "svc = SVC(kernel='linear',gamma='auto',probability=True)\n",
        "svc.fit(X_train,y_train)\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "sgd = SGDClassifier(max_iter=1000, tol=1e-4)\n",
        "sgd.fit(X_train,y_train)\n",
        "y_pred_sgd = sgd.predict(X_test)\n",
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train,y_train)\n",
        "y_pred_ada = ada.predict(X_test)\n",
        "decc = DecisionTreeClassifier()\n",
        "decc.fit(X_train,y_train)\n",
        "y_pred_decc = decc.predict(X_test)\n",
        "gbm = GradientBoostingClassifier(n_estimators=100,max_features='sqrt')\n",
        "gbm.fit(X_train,y_train)\n",
        "y_pred_gbm = gbm.predict(X_test)\n",
        "data = {\n",
        "             'Random Forest Entropy': y_pred_rfe, \n",
        "                'MLP2': y_pred_mlp, \n",
        "                'KNN2': y_pred_knn, \n",
        "                'EXtra tree classifier': y_pred_et1000,\n",
        "                'XGB2': y_pred_xgb, \n",
        "                'SVC2': y_pred_svc, \n",
        "                'SGD2': y_pred_sgd,\n",
        "                'Adaboost': y_pred_ada, \n",
        "                'CART': y_pred_decc, \n",
        "                'GBM': y_pred_gbm }\n",
        "\n",
        "models = pd.DataFrame(data) \n",
        " \n",
        "for column in models:\n",
        "    CM=confusion_matrix(y_test,models[column])\n",
        "    \n",
        "    TN = CM[0][0]\n",
        "    FN = CM[1][0]\n",
        "    TP = CM[1][1]\n",
        "    FP = CM[0][1]\n",
        "    specificity = TN/(TN+FP)\n",
        "    loss_log = log_loss(y_test, models[column])\n",
        "    acc= accuracy_score(y_test, models[column])\n",
        "    roc=roc_auc_score(y_test, models[column])\n",
        "    prec = precision_score(y_test, models[column])\n",
        "    rec = recall_score(y_test, models[column])\n",
        "    f1 = f1_score(y_test, models[column])\n",
        "    \n",
        "    mathew = matthews_corrcoef(y_test, models[column])\n",
        "    results =pd.DataFrame([[column,acc, prec,rec,specificity, f1,roc, loss_log,mathew]],\n",
        "               columns = ['Model', 'Accuracy','Precision', 'Sensitivity','Specificity', 'F1 Score','ROC','Log_Loss','mathew_corrcoef'])\n",
        "    model_results = model_results.append(results, ignore_index = True)\n",
        "\n",
        "model_results"
      ],
      "metadata": {
        "id": "nTNyQvQRpMnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roc_auc_plot(y_true, y_proba, label=' ', l='-', lw=1.0):\n",
        "    from sklearn.metrics import roc_curve, roc_auc_score\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba[:,1])\n",
        "    ax.plot(fpr, tpr, linestyle=l, linewidth=lw,\n",
        "            label=\"%s (area=%.3f)\"%(label,roc_auc_score(y_true, y_proba[:,1])))\n",
        "\n",
        "f, ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "roc_auc_plot(y_test,eclf1.predict_proba(X_test),label='Soft Voting Classifier ',l='-')\n",
        "roc_auc_plot(y_test,rf_ent.predict_proba(X_test),label='Random Forest Classifier ',l='-')\n",
        "roc_auc_plot(y_test,et_1000.predict_proba(X_test),label='Extra Tree Classifier ',l='-')\n",
        "roc_auc_plot(y_test,xgb.predict_proba(X_test),label='XGboost',l='-')\n",
        "\n",
        "ax.plot([0,1], [0,1], color='k', linewidth=0.5, linestyle='--', \n",
        "        )    \n",
        "ax.legend(loc=\"lower right\")    \n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "ax.set_title('Receiver Operator Characteristic curves')\n",
        "sns.despine()"
      ],
      "metadata": {
        "id": "NwVjv9ntpRpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_plot(y_true, y_proba, label=' ', l='-', lw=1.0):\n",
        "    from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "    precision, recall, _ = precision_recall_curve(y_test,\n",
        "                                                  y_proba[:,1])\n",
        "    average_precision = average_precision_score(y_test, y_proba[:,1],\n",
        "                                                     average=\"micro\")\n",
        "    ax.plot(recall, precision, label='%s (average=%.3f)'%(label,average_precision),\n",
        "            linestyle=l, linewidth=lw)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(14,10))\n",
        "precision_recall_plot(y_test,eclf1.predict_proba(X_test),label='Soft voting classifier ',l='-')\n",
        "precision_recall_plot(y_test,rf_ent.predict_proba(X_test),label='Random Forest Classifier ',l='-')\n",
        "precision_recall_plot(y_test,et_1000.predict_proba(X_test),label='Extra Tree Classifier ',l='-')\n",
        "precision_recall_plot(y_test,xgb.predict_proba(X_test),label='XGboost',l='-')\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.legend(loc=\"lower left\")\n",
        "ax.grid(True)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "ax.set_title('Precision-recall curves')\n",
        "sns.despine()"
      ],
      "metadata": {
        "id": "g4VSwxaopRrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Importance"
      ],
      "metadata": {
        "id": "9VCLlihYpbRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feat_importances = pd.Series(rf_ent.feature_importances_, index=X_train.columns)\n",
        "feat_importances.nlargest(20).plot(kind='barh')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "BfqEiapopRuB",
        "outputId": "e22243c5-8895-4d90-c4f8-c8a699e2c50a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f353ce661d0>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7feCLGadpRwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z_2Li1bDoV0H"
      }
    }
  ]
}